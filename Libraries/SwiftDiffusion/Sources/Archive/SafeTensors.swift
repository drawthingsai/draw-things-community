import C_ccv
import Fickling
import Foundation
import NNC

// Need to double check, this is generated by ChatGPT, double-checked with https://lambdalabs.com/blog/nvidia-hopper-h100-and-fp8-support
public let F8_E4M3: [Float] = [
  0.0, 0.001953125, 0.00390625, 0.005859375, 0.0078125, 0.009765625, 0.01171875, 0.013671875,
  0.015625, 0.017578125, 0.01953125, 0.021484375, 0.0234375, 0.025390625, 0.02734375, 0.029296875,
  0.03125, 0.03515625, 0.0390625, 0.04296875, 0.046875, 0.05078125, 0.0546875, 0.05859375, 0.0625,
  0.0703125, 0.078125, 0.0859375, 0.09375, 0.1015625, 0.109375, 0.1171875, 0.125, 0.140625, 0.15625,
  0.171875, 0.1875, 0.203125, 0.21875, 0.234375, 0.25, 0.28125, 0.3125, 0.34375, 0.375, 0.40625,
  0.4375, 0.46875, 0.5, 0.5625, 0.625, 0.6875, 0.75, 0.8125, 0.875, 0.9375, 1.0, 1.125, 1.25, 1.375,
  1.5, 1.625, 1.75, 1.875, 2.0, 2.25, 2.5, 2.75, 3.0, 3.25, 3.5, 3.75, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5,
  7.0, 7.5, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 18.0, 20.0, 22.0, 24.0, 26.0, 28.0,
  30.0, 32.0, 36.0, 40.0, 44.0, 48.0, 52.0, 56.0, 60.0, 64.0, 72.0, 80.0, 88.0, 96.0, 104.0, 112.0,
  120.0, 128.0, 144.0, 160.0, 176.0, 192.0, 208.0, 224.0, 240.0, 256.0, 288.0, 320.0, 352.0, 384.0,
  416.0, 448.0, .nan, -0.0, -0.001953125, -0.00390625, -0.005859375, -0.0078125, -0.009765625,
  -0.01171875, -0.013671875, -0.015625, -0.017578125, -0.01953125, -0.021484375, -0.0234375,
  -0.025390625, -0.02734375, -0.029296875, -0.03125, -0.03515625, -0.0390625, -0.04296875,
  -0.046875, -0.05078125, -0.0546875, -0.05859375, -0.0625, -0.0703125, -0.078125, -0.0859375,
  -0.09375, -0.1015625, -0.109375, -0.1171875, -0.125, -0.140625, -0.15625, -0.171875, -0.1875,
  -0.203125, -0.21875, -0.234375, -0.25, -0.28125, -0.3125, -0.34375, -0.375, -0.40625, -0.4375,
  -0.46875, -0.5, -0.5625, -0.625, -0.6875, -0.75, -0.8125, -0.875, -0.9375, -1.0, -1.125, -1.25,
  -1.375, -1.5, -1.625, -1.75, -1.875, -2.0, -2.25, -2.5, -2.75, -3.0, -3.25, -3.5, -3.75, -4.0,
  -4.5, -5.0, -5.5, -6.0, -6.5, -7.0, -7.5, -8.0, -9.0, -10.0, -11.0, -12.0, -13.0, -14.0, -15.0,
  -16.0, -18.0, -20.0, -22.0, -24.0, -26.0, -28.0, -30.0, -32.0, -36.0, -40.0, -44.0, -48.0, -52.0,
  -56.0, -60.0, -64.0, -72.0, -80.0, -88.0, -96.0, -104.0, -112.0, -120.0, -128.0, -144.0, -160.0,
  -176.0, -192.0, -208.0, -224.0, -240.0, -256.0, -288.0, -320.0, -352.0, -384.0, -416.0, -448,
  .nan,
]

public let F8_E5M2: [Float] = [
  0.0, 1.52587890625e-05, 3.0517578125e-05, 4.57763671875e-05, 6.103515625e-05, 7.62939453125e-05,
  9.1552734375e-05, 0.0001068115234375, 0.0001220703125, 0.000152587890625, 0.00018310546875,
  0.000213623046875, 0.000244140625, 0.00030517578125, 0.0003662109375, 0.00042724609375,
  0.00048828125, 0.0006103515625, 0.000732421875, 0.0008544921875, 0.0009765625, 0.001220703125,
  0.00146484375, 0.001708984375, 0.001953125, 0.00244140625, 0.0029296875, 0.00341796875,
  0.00390625, 0.0048828125, 0.005859375, 0.0068359375, 0.0078125, 0.009765625, 0.01171875,
  0.013671875, 0.015625, 0.01953125, 0.0234375, 0.02734375, 0.03125, 0.0390625, 0.046875, 0.0546875,
  0.0625, 0.078125, 0.09375, 0.109375, 0.125, 0.15625, 0.1875, 0.21875, 0.25, 0.3125, 0.375, 0.4375,
  0.5, 0.625, 0.75, 0.875, 1.0, 1.25, 1.5, 1.75, 2.0, 2.5, 3.0, 3.5, 4.0, 5.0, 6.0, 7.0, 8.0, 10.0,
  12.0, 14.0, 16.0, 20.0, 24.0, 28.0, 32.0, 40.0, 48.0, 56.0, 64.0, 80.0, 96.0, 112.0, 128.0, 160.0,
  192.0, 224.0, 256.0, 320.0, 384.0, 448.0, 512.0, 640.0, 768.0, 896.0, 1024.0, 1280.0, 1536.0,
  1792.0, 2048.0, 2560.0, 3072.0, 3584.0, 4096.0, 5120.0, 6144.0, 7168.0, 8192.0, 10240.0, 12288.0,
  14336.0, 16384.0, 20480.0, 24576.0, 28672.0, 32768.0, 40960.0, 49152.0, 57344.0, .infinity, .nan,
  .nan, .nan, -0.0, -1.52587890625e-05, -3.0517578125e-05, -4.57763671875e-05, -6.103515625e-05,
  -7.62939453125e-05, -9.1552734375e-05, -0.0001068115234375, -0.0001220703125, -0.000152587890625,
  -0.00018310546875, -0.000213623046875, -0.000244140625, -0.00030517578125, -0.0003662109375,
  -0.00042724609375, -0.00048828125, -0.0006103515625, -0.000732421875, -0.0008544921875,
  -0.0009765625, -0.001220703125, -0.00146484375, -0.001708984375, -0.001953125, -0.00244140625,
  -0.0029296875, -0.00341796875, -0.00390625, -0.0048828125, -0.005859375, -0.0068359375,
  -0.0078125, -0.009765625, -0.01171875, -0.013671875, -0.015625, -0.01953125, -0.0234375,
  -0.02734375, -0.03125, -0.0390625, -0.046875, -0.0546875, -0.0625, -0.078125, -0.09375, -0.109375,
  -0.125, -0.15625, -0.1875, -0.21875, -0.25, -0.3125, -0.375, -0.4375, -0.5, -0.625, -0.75, -0.875,
  -1.0, -1.25, -1.5, -1.75, -2.0, -2.5, -3.0, -3.5, -4.0, -5.0, -6.0, -7.0, -8.0, -10.0, -12.0,
  -14.0, -16.0, -20.0, -24.0, -28.0, -32.0, -40.0, -48.0, -56.0, -64.0, -80.0, -96.0, -112.0,
  -128.0, -160.0, -192.0, -224.0, -256.0, -320.0, -384.0, -448.0, -512.0, -640.0, -768.0, -896.0,
  -1024.0, -1280.0, -1536.0, -1792.0, -2048.0, -2560.0, -3072.0, -3584.0, -4096.0, -5120.0, -6144.0,
  -7168.0, -8192.0, -10240.0, -12288.0, -14336.0, -16384.0, -20480.0, -24576.0, -28672.0, -32768.0,
  -40960.0, -49152.0, -57344.0, -.infinity, .nan, .nan, .nan,
]

public final class SafeTensors {
  public var data: Data
  public let bufferStart: Int
  public let states: [String: TensorDescriptor]
  public init?(url: URL) {
    guard let data = try? Data(contentsOf: url, options: .mappedIfSafe) else { return nil }
    guard data.count >= 8 else { return nil }
    let headerSize = data.withUnsafeBytes { $0.load(as: UInt64.self) }
    // It doesn't make sense for my use-case has more than 10MiB header.
    guard headerSize > 0 && headerSize < data.count + 8 && headerSize < 1_024 * 1_024 * 10 else {
      return nil
    }
    guard
      let jsonDict = try? JSONSerialization.jsonObject(
        with: data[8..<(8 + headerSize)]) as? [String: Any]
    else { return nil }
    var states = [String: TensorDescriptor]()
    for (key, value) in jsonDict {
      guard let value = value as? [String: Any], let offsets = value["data_offsets"] as? [Int],
        let dtype = (value["dtype"] as? String)?.lowercased(), var shape = value["shape"] as? [Int],
        offsets.count == 2 && shape.count >= 0
      else { continue }
      let offsetStart = offsets[0]
      let offsetEnd = offsets[1]
      guard offsetEnd > offsetStart && offsetEnd <= data.count else {
        continue
      }
      if shape.count == 0 {
        shape = [1]
      }
      guard !(shape.contains { $0 <= 0 }) else {
        continue
      }
      guard
        dtype == "f32" || dtype == "f16" || dtype == "float16" || dtype == "float32"
          || dtype == "float" || dtype == "half" || dtype == "float64" || dtype == "f64"
          || dtype == "double" || dtype == "bf16" || dtype == "bfloat16" || dtype == "f8_e4m3"
          || dtype == "f8_e5m2"
      else {
        continue
      }
      let BF16 = (dtype == "bf16" || dtype == "bfloat16")
      let FP8_E4M3 = (dtype == "f8_e4m3")
      let FP8_E5M2 = (dtype == "f8_e5m2")
      let dataType: DataType
      if dtype == "f32" || dtype == "float32" || dtype == "float" {
        dataType = .Float32
      } else if dtype == "f64" || dtype == "float64" || dtype == "double" {
        dataType = .Float64
      } else if dtype == "f8_e4m3" || dtype == "f8_e5m2" {
        dataType = .UInt8
      } else {
        dataType = .Float16
      }
      var strides = [Int]()
      var v = 1
      for i in stride(from: shape.count - 1, through: 0, by: -1) {
        strides.append(v)
        v *= shape[i]
      }
      strides.reverse()
      let tensorDescriptor = TensorDescriptor(
        storage: Storage(
          name: key, size: offsetEnd - offsetStart, dataType: dataType, BF16: BF16,
          FP8_E4M3: FP8_E4M3, FP8_E5M2: FP8_E5M2),
        storageOffset: offsetStart, shape: shape, strides: strides)
      states[key] = tensorDescriptor
    }
    self.data = data
    self.states = states
    bufferStart = 8 + Int(headerSize)
  }
}

public protocol TensorDataArchive: TensorArchive, AnyObject {
  var data: Data { get }
  var bufferStart: Int { get }
}

extension SafeTensors: TensorDataArchive {
}

extension TensorDataArchive {
  public func with<T>(_ tensorDescriptor: TensorDescriptor, block: (AnyTensor) throws -> T) throws
    -> T
  {
    // Don't subrange data, otherwise it will materialize the data into memory. Accessing the underlying
    // bytes directly, this way, it is just the mmap bytes, and we won't cause spike in memory usage.
    return try data.withUnsafeBytes {
      guard let address = $0.baseAddress else { throw InflateError.dataNoBaseAddress }
      if Interpreter.inflateInterrupter?() ?? false {
        throw InflateError.interrupted
      }
      let tensor: AnyTensor
      #if !((os(macOS) || (os(iOS) && targetEnvironment(macCatalyst))) && (arch(i386) || arch(x86_64)))
        if tensorDescriptor.storage.dataType == .Float16 {
          if tensorDescriptor.storage.BF16 {
            let count = tensorDescriptor.strides[0] * tensorDescriptor.shape[0]
            let u16 = UnsafeMutablePointer<UInt16>.allocate(capacity: count * 2)
            let bf16 = (address + bufferStart + tensorDescriptor.storageOffset).assumingMemoryBound(
              to: UInt16.self)
            for i in 0..<count {
              u16[i * 2] = 0
              u16[i * 2 + 1] = bf16[i]
            }
            tensor = Tensor<Float>(
              .CPU, format: .NCHW, shape: TensorShape(tensorDescriptor.shape),
              unsafeMutablePointer: UnsafeMutableRawPointer(u16).assumingMemoryBound(
                to: Float.self), bindLifetimeOf: self
            ).copied()
            u16.deallocate()
          } else {
            tensor = Tensor<Float16>(
              .CPU, format: .NCHW, shape: TensorShape(tensorDescriptor.shape),
              unsafeMutablePointer: UnsafeMutableRawPointer(
                mutating: address + bufferStart + tensorDescriptor.storageOffset
              )
              .assumingMemoryBound(
                to: Float16.self), bindLifetimeOf: self
            ).copied()
          }
        } else if tensorDescriptor.storage.dataType == .Float64 {
          tensor = Tensor<Double>(
            .CPU, format: .NCHW, shape: TensorShape(tensorDescriptor.shape),
            unsafeMutablePointer: UnsafeMutableRawPointer(
              mutating: address + bufferStart + tensorDescriptor.storageOffset
            )
            .assumingMemoryBound(
              to: Double.self), bindLifetimeOf: self
          )
        } else if tensorDescriptor.storage.dataType == .UInt8 {
          let count = tensorDescriptor.strides[0] * tensorDescriptor.shape[0]
          let fp8 = (address + bufferStart + tensorDescriptor.storageOffset).assumingMemoryBound(
            to: UInt8.self)
          var f32 = Tensor<Float>(
            .CPU, format: .NCHW, shape: TensorShape(tensorDescriptor.shape)
          )
          f32.withUnsafeMutableBytes {
            guard let f32 = $0.baseAddress?.assumingMemoryBound(to: Float.self) else { return }
            if tensorDescriptor.storage.FP8_E4M3 {
              for i in 0..<count {
                f32[i] = F8_E4M3[Int(fp8[i])]
              }
            } else if tensorDescriptor.storage.FP8_E5M2 {
              for i in 0..<count {
                f32[i] = F8_E5M2[Int(fp8[i])]
              }
            }
          }
          tensor = f32
        } else {
          tensor = Tensor<Float>(
            .CPU, format: .NCHW, shape: TensorShape(tensorDescriptor.shape),
            unsafeMutablePointer: UnsafeMutableRawPointer(
              mutating: address + bufferStart + tensorDescriptor.storageOffset
            )
            .assumingMemoryBound(
              to: Float.self), bindLifetimeOf: self
          )
        }
      #else
        if tensorDescriptor.storage.dataType == .Float16 {
          let count = tensorDescriptor.strides[0] * tensorDescriptor.shape[0]
          let u16 = UnsafeMutablePointer<UInt16>.allocate(capacity: count * 2)
          let f16 = (address + bufferStart + tensorDescriptor.storageOffset).assumingMemoryBound(
            to: UInt16.self)
          if tensorDescriptor.storage.BF16 {
            for i in 0..<count {
              u16[i * 2] = 0
              u16[i * 2 + 1] = f16[i]
            }
          } else {
            ccv_half_precision_to_float(
              f16, UnsafeMutableRawPointer(u16).assumingMemoryBound(to: Float.self), count)
          }
          tensor = Tensor<Float>(
            .CPU, format: .NCHW, shape: TensorShape(tensorDescriptor.shape),
            unsafeMutablePointer: UnsafeMutableRawPointer(u16).assumingMemoryBound(
              to: Float.self), bindLifetimeOf: self
          ).copied()
          u16.deallocate()
        } else if tensorDescriptor.storage.dataType == .Float64 {
          tensor = Tensor<Double>(
            .CPU, format: .NCHW, shape: TensorShape(tensorDescriptor.shape),
            unsafeMutablePointer: UnsafeMutableRawPointer(
              mutating: address + bufferStart + tensorDescriptor.storageOffset
            )
            .assumingMemoryBound(
              to: Double.self), bindLifetimeOf: self
          )
        } else if tensorDescriptor.storage.dataType == .UInt8 {
          let count = tensorDescriptor.strides[0] * tensorDescriptor.shape[0]
          let fp8 = (address + bufferStart + tensorDescriptor.storageOffset).assumingMemoryBound(
            to: UInt8.self)
          var f32 = Tensor<Float>(
            .CPU, format: .NCHW, shape: TensorShape(tensorDescriptor.shape)
          )
          f32.withUnsafeMutableBytes {
            guard let f32 = $0.baseAddress?.assumingMemoryBound(to: Float.self) else { return }
            if tensorDescriptor.storage.FP8_E4M3 {
              for i in 0..<count {
                f32[i] = F8_E4M3[Int(fp8[i])]
              }
            } else if tensorDescriptor.storage.FP8_E5M2 {
              for i in 0..<count {
                f32[i] = F8_E5M2[Int(fp8[i])]
              }
            }
          }
          tensor = f32
        } else {
          tensor = Tensor<Float>(
            .CPU, format: .NCHW, shape: TensorShape(tensorDescriptor.shape),
            unsafeMutablePointer: UnsafeMutableRawPointer(
              mutating: address + bufferStart + tensorDescriptor.storageOffset
            )
            .assumingMemoryBound(
              to: Float.self), bindLifetimeOf: self
          ).copied()
        }
      #endif
      return try block(tensor)
    }
  }
}
